{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "788cd29b-00ec-47c6-940f-2e2b0a1e12a1",
   "metadata": {},
   "source": [
    "#### MAIN: In a Binomial model of a single stock with non-zero interest rate, assume that we can hedge any fraction of a stock, use policy gradient to train the optimal policy of hedging an ATM American put option with maturity T = 10. WHEN do you early exercise the option? Is your solution same as what you obtain from delta hedging?\n",
    "\n",
    "#### OPTIONAL: For really advanced students: supppose the stock follows a GBM (Geometric Brownian Motion), construct an algorithm to train a Neural Network that hedges an ATM American Put Option\n",
    "\n",
    "#### OPTIONAL BONUS: After solving the optional question, sue the Soft Actor Critic algorithm in TF agent to solve the problem again in the colab.resarch.google.com environment. Compare your results\n",
    "\n",
    "#### ADVANCED EXTRA BONUS: Implement the GAC algorithm using the TF agent library and solve the optinal problem"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1fab16d2-8131-4773-8ff0-8cbee33a6913",
   "metadata": {},
   "source": [
    "### Lets Start With Simple Single Time Step European Option in Binomial Price Setting"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "24b2fed6-8f32-4478-b88e-7e3d93508959",
   "metadata": {},
   "outputs": [],
   "source": [
    "from __future__ import annotations\n",
    "#### Action - exercise/not exercise\n",
    "#### Reward - Utility(Payoff)\n",
    "#### Transition -> Prices of Stock\n",
    "from dataclasses import dataclass\n",
    "from collections import defaultdict\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "import torch.optim as optim\n",
    "import torch.autograd as autograd\n",
    "from torch.distributions import MultivariateNormal, Normal\n",
    "import numpy as np\n",
    "from tqdm import tqdm\n",
    "from scipy.special import comb\n",
    "import math\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "'''\n",
    "Constraints:\n",
    "1. Assuming you can hedge any fraction of stock\n",
    "2. Assume Complete Market for now, Price_down <= Price_original * (1+r) <= Price_up <-- Otherwise there will be arbitrage\n",
    "3. 1 risky asset\n",
    "'''\n",
    "@dataclass(frozen=True)\n",
    "class HedgePortfolioState:\n",
    "    time: tensor\n",
    "    hedge_ratio: tensor\n",
    "    current_price: tensor \n",
    "    terminal_time: tensor\n",
    "    \n",
    "    def __eq__(self, other):\n",
    "        return (self.time == other.time) and \\\n",
    "               (self.current_price == other.current_price) and \\\n",
    "               (self.hedge_ratio == other.hedge_ratio)\n",
    "    \n",
    "    def get_features(self):\n",
    "        return [self.time,self.current_price,self.hedge_ratio]\n",
    "    \n",
    "    def isTerminal(self):\n",
    "        return self.time >= self.terminal_time\n",
    "    \n",
    "@dataclass(frozen=True)\n",
    "class HedgeAction:\n",
    "    hedge_ratio: tensor\n",
    "\n",
    "class HedgePolicy(nn.Module):\n",
    "    def __init__(self, state_dim, action_dim):\n",
    "        super(HedgePolicy, self).__init__()\n",
    "        self.linear = nn.Linear(state_dim,action_dim)\n",
    "        \n",
    "    def forward(self, state):\n",
    "        state.requires_grad=True\n",
    "        action = self.linear(state)\n",
    "        return action\n",
    "\n",
    "#take care of one_step case\n",
    "def binomial_price(current_price, strike_price, risk_free_rate, time, termination_time, up_factor, down_factor):\n",
    "    change_in_time = time/termination_time\n",
    "    #Risk-neutral probability - p\n",
    "    p = ((1+risk_free_rate) - down_factor)/(up_factor - down_factor)\n",
    "    payoff_up = max(current_price * up_factor - strike_price,0)\n",
    "    payoff_down = max(current_price * down_factor - strike_price,0)\n",
    "    # print(f'p = {p}, payoff_up = {payoff_up}, payoff_down={payoff_down}')\n",
    "    # option_price= p * payoff_up + (1-p) * payoff_down\n",
    "    option_price=0\n",
    "    for t in range(termination_time+1):\n",
    "        price = current_price * (up_factor ** (t)) * (down_factor ** (termination_time-t))\n",
    "        payoff = max(price - strike_price, 0)\n",
    "        #calculate nCr for binomial tree to get expected payoffs\n",
    "        option_price += payoff * comb(termination_time,t) * (p ** t) * ((1-p) ** (termination_time - t))\n",
    "    \n",
    "    option_price *= math.exp(-risk_free_rate * time) #Assumes continuous compounding\n",
    "    return option_price\n",
    "\n",
    "def reward_function(prev_state,state,action,strike_price,risk_free_rate,up_factor,down_factor):\n",
    "    #Calculate hedging cost:\n",
    "    prev_price = prev_state.current_price\n",
    "    current_price = state.current_price\n",
    "    hedge_change = (prev_state.hedge_ratio + action) * torch.tensor(current_price - prev_price)\n",
    "    payoff = torch.max(state.current_price - torch.tensor(strike_price),torch.tensor(0.0))\n",
    "    #this is the cash you get for selling the call option\n",
    "    option_price = binomial_price(prev_state.current_price,\n",
    "                                  strike_price,\n",
    "                                  risk_free_rate,\n",
    "                                  prev_state.time,\n",
    "                                  state.terminal_time,\n",
    "                                  up_factor,\n",
    "                                  down_factor\n",
    "                                 )\n",
    "    cash = option_price - (action * prev_price)\n",
    "    hedge = action * current_price\n",
    "    delta = torch.abs(payoff - (hedge + cash))\n",
    "    return delta\n",
    "\n",
    "class OptionEnvironment():\n",
    "    def __init__(self, strike_price,init_stock_price,binomial_price_dist,risk_free_rate,termination_time):\n",
    "        self.strike_price=strike_price\n",
    "        self.init_stock_price=init_stock_price\n",
    "        self.stock_price=init_stock_price\n",
    "        self.binomial_price_dist=binomial_price_dist\n",
    "        self.risk_free_rate=risk_free_rate\n",
    "        self.time_step = 0\n",
    "        self.termination_time=termination_time\n",
    "    \n",
    "    def reset(self):\n",
    "        self.time_step = 0\n",
    "        init_state = HedgePortfolioState(time=0,\n",
    "                                         current_price=torch.tensor(self.init_stock_price),\n",
    "                                         hedge_ratio=torch.tensor(0.0),\n",
    "                                         terminal_time=self.termination_time)\n",
    "        return init_state\n",
    "    \n",
    "    def step(self,state,action):\n",
    "        self.time_step += 1\n",
    "        #Update state given an action (hedge)\n",
    "        price_change = np.random.choice([*self.binomial_price_dist.keys()], p=[*self.binomial_price_dist.values()])\n",
    "        next_price = state.current_price * price_change\n",
    "        next_state = HedgePortfolioState(time=self.time_step,\n",
    "                                         hedge_ratio=action.item() + state.hedge_ratio,\n",
    "                                         current_price=torch.tensor(next_price),\n",
    "                                         terminal_time=self.termination_time)\n",
    "        #reward:\n",
    "        up = [*self.binomial_price_dist.keys()][0]\n",
    "        down = [*self.binomial_price_dist.keys()][1]\n",
    "        reward = reward_function(state,next_state,action,self.strike_price,self.risk_free_rate,up,down)\n",
    "        return next_state, reward\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "0dcef3f2-bc57-4f05-ac0d-80d20035a106",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "6.0"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "binomial_price(100, 102, 0, 0, 1, 1.2, 0.9)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "750ebe19-e40e-4d41-a06a-f2a9858af40f",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  0%|          | 0/5000 [00:00<?, ?it/s]/Users/clemmie/opt/anaconda3/envs/Python3_7_Plus_R/lib/python3.7/site-packages/ipykernel_launcher.py:121: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "/Users/clemmie/opt/anaconda3/envs/Python3_7_Plus_R/lib/python3.7/site-packages/ipykernel_launcher.py:80: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "100%|██████████| 5000/5000 [00:07<00:00, 675.33it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "State: HedgePortfolioState(time=0, hedge_ratio=tensor(0.), current_price=tensor(100), terminal_time=2), Action: 0.5710234642028809\n",
      "State: HedgePortfolioState(time=1, hedge_ratio=tensor(0.5710), current_price=tensor(90.), terminal_time=2), Action: 0.829270601272583\n"
     ]
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "\n",
    "'''\n",
    "So one of the standard function approximator for the actor is the linear gaussian approximator --> Linear Gaussian Policy.\n",
    "Even though I don't think the policy will be stochastic... I believe if you approximate it with Linear Gaussian Policy, what you will\n",
    "end up with is some mean with close to zero variance to depict the fact that its basically deterministic\n",
    "'''\n",
    "\n",
    "def train():\n",
    "    learning_rate=1e-3\n",
    "    num_eps = 5000\n",
    "    state_dim=3\n",
    "    action_dim=1\n",
    "    strike_price=102\n",
    "    risk_free_rate = torch.tensor(0.0)\n",
    "    price_up = torch.tensor(1.2)\n",
    "    price_down =torch.tensor(0.9)\n",
    "    probability_price_up=torch.tensor(0.6)\n",
    "    binomial_price_changes = {\n",
    "        price_up:probability_price_up,\n",
    "        price_down:1-probability_price_up\n",
    "    }\n",
    "    TERMINAL_TIME=2\n",
    "\n",
    "    env = OptionEnvironment(strike_price,100,binomial_price_changes,risk_free_rate,TERMINAL_TIME)\n",
    "    policy = HedgePolicy(state_dim,action_dim)\n",
    "    \n",
    "    optimizer = optim.Adam(policy.parameters(),lr=learning_rate)\n",
    "    \n",
    "    record_loss = []\n",
    "    for episode in tqdm(range(num_eps)):\n",
    "        state = env.reset()\n",
    "        \n",
    "        log_probs= []\n",
    "        rewards = []\n",
    "        while True:\n",
    "            state_features = state.get_features()\n",
    "            state_tensor = torch.FloatTensor(state_features)\n",
    "            state_tensor.requires_grad=True\n",
    "            action = policy(state_tensor) #this calls forward\n",
    "            next_state, reward = env.step(state, action)\n",
    "            rewards.append(reward)\n",
    "            if next_state.isTerminal():\n",
    "                break\n",
    "            \n",
    "            state = next_state\n",
    "            \n",
    "        ##Monte Carlo Policy Gradient with TD(0) reward\n",
    "        returns = []\n",
    "        G = torch.tensor(0.0)\n",
    "        for r in reversed(rewards):\n",
    "            G = r + 0.99 * G\n",
    "            returns.insert(0,G)\n",
    "            \n",
    "        loss = torch.tensor(0.0)\n",
    "        for g in returns:\n",
    "            loss += g[0]\n",
    "        \n",
    "        record_loss.append(loss)\n",
    "        optimizer.zero_grad()\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "    \n",
    "    state = env.reset()\n",
    "    x_axis = np.arange(1,len(record_loss)+1)\n",
    "\n",
    "    plt.plot(x_axis,[x.detach().numpy() for x in record_loss], label='loss')\n",
    "    plt.legend()\n",
    "    \n",
    "    while True:\n",
    "        state_features = state.get_features()\n",
    "        state_tensor = torch.FloatTensor(state_features)\n",
    "        action = policy(state_tensor)\n",
    "        print(f'State: {state}, Action: {action.item()}')\n",
    "        next_state, _ = env.step(state,action)\n",
    "        if next_state.isTerminal():\n",
    "            break\n",
    "        \n",
    "        state = next_state\n",
    "    \n",
    "train()\n",
    "\n",
    "#https://edisciplinas.usp.br/pluginfile.php/5278790/mod_resource/content/1/Hull%20J.C.-Options%2C%20Futures%20and%20Other%20Derivatives_9th%20edition.pdf\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "636d4381-ce68-49ae-9336-248a93c40511",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
