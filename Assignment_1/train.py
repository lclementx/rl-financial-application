from random import random
from math import exp
from regression import QRegressor


'''
This file create an agent that can handle continous action and wealth using Monte Carlo method
The agent was trained via regression to esitmate the Q function base on data generated by Monte Carlo method
'''

# Generate random action in the range of -2 to 3
def random_agent():
    return 5 * random() - 2


# Get the next state and rewards, with optional deterministic transition from the luck variable
def get_next_state(t, Wt, xt, a, b, p, r, alpha=1, luck=None):
    if luck is None:
        Yt = a if random() < p else b
    else:
        Yt = a if luck == 1 else b
    next_W = xt * (Yt - r) + Wt * (1 + r)
    if t == 10:
        reward = -exp(-alpha * next_W) / alpha
    else:
        reward = 0
    return next_W, reward


# Generate training sample in a Monte Carlo fashion
def generate_sample(Q, W, a, b, p, r, T, N=1000, alpha=1, epsilon=1):
    
    states = []
    rewards = []
    for _ in range(N):
        Wt = W
        state = []
        for t in range(T):
            if random() < epsilon:
                xt = random_agent()
            else:
                xt, _ = Q[t].find_max(Wt)
            next_W, reward = get_next_state(t + 1, Wt, xt, a, b, p, r, alpha)
            state.append([Wt, xt])
            Wt = next_W
            if reward != 0:
                rewards.append(reward)
        states.append(state)
    return states, rewards


# Function to get the average reward obtained by a trained agent, with option for determinstic transition path in the fate variable
def test_agent(Q, W, a, b, p, r, T, N=100, alpha=1, fate=None):
    
    rewards = 0
    for i in range(N):
        Wt = W
        for t in range(T):
            xt, _ = Q[t].find_max(Wt)
            luck = None if fate is None else fate[i][t]
            next_W, reward = get_next_state(t + 1, Wt, xt, a, b, p, r, alpha, luck)
            Wt = next_W
            rewards += reward
    return rewards


# Function to get the average reward obtained by a random agent, with option for determinstic transition path in the fate variable
def test_random_agent(W, a, b, p, r, T, N=100, alpha=1, fate=None):

    rewards = 0
    for i in range(N):
        Wt = W
        for t in range(T):
            xt = random_agent()
            f = None if fate is None else fate[i][t]
            next_W, reward = get_next_state(t + 1, Wt, xt, a, b, p, r, alpha, f)
            Wt = next_W
            rewards += reward
    return rewards


# Generate a set of binary determinstic transition with the probability of 1 being p
def generate_fate(p, T=10, n=20):
    fate = []
    for i in range(n):
        fate.append([])
        for t in range(T):
            fate[i].append(int(p > random()))
    return fate


# Train a regression model from generated experience
def train_regression(states, rewards, T=10, N=1000):
    Q = {}
    W = {}
    X = {}
    R = {}
    for t in range(T):
        Q[t] = QRegressor()
        W[t] = []
        X[t] = []
        R[t] = []
        for i in range(N):
            Wt, xt = states[i][t]
            W[t].append(Wt)
            X[t].append(xt)
            R[t].append(rewards[i])
        Q[t].train(W[t], X[t], R[t])
    return Q
        

# Environment properties
W0 = 1
T = 10
a = 0.3
b = -0.1
p = 0.6
r = 0.05
alpha = 1

# Evaluate the performacne of a random agent
test_fate = generate_fate(p, T, 50)
random_agent_performance = test_random_agent(W0, a, b, p, r, T, 50, alpha, test_fate) / 50 + 1
print('Random agent average final rewards:', random_agent_performance)

# Train an agent using Monte Carlo method by generating sample and doing regression on the Q function
eps = 1
model = None
for j in range(3):
    states, rewards = generate_sample(model, W0, a, b, p, r, T, N=2000, epsilon=eps)
    model = train_regression(states, rewards, T, N=2000)
    agent_performance = test_agent(model, W0, a, b, p, r, T, 50, alpha, test_fate) / 50 + 1
    print(f'Episode {j + 1} trained agent average final rewards:', agent_performance)
    eps *= 0.8

# Plot a slice of learned Q function at T = 10 and W = 1 for sanity check
model[9].plotSlice(1)