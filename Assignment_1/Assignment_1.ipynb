{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "8991e8fa-b26b-4767-9d09-ba7340b0c86a",
   "metadata": {},
   "outputs": [],
   "source": [
    "%load_ext autoreload\n",
    "%autoreload 2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "18455f32-a8b9-45cd-9f53-cf97152aa48d",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'Consider the discrete-time asset allocation example in section 8.4 of Rao and Jelvis. Suppose the single-time-step return of the risky asset from time t to t+1 as Yt = a, prob = p\\nand b, prob = (1-p). Suppose that T=10, use the TD method to find the Q function and hence the optimal strategy'"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "'''Consider the discrete-time asset allocation example in section 8.4 of Rao and Jelvis. Suppose the single-time-step return of the risky asset from time t to t+1 as Yt = a, prob = p\n",
    "and b, prob = (1-p). Suppose that T=10, use the TD method to find the Q function and hence the optimal strategy'''"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "b8f393e6-767d-4fa9-a6f0-f56d63c34436",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "defaultdict(<class 'float'>, {(WealthState(time=0, wealth=-1, risky_asset_allocation=0, termination_time=3), InvestmentAction(risky_investment_amount=0)): -7.699875968629806, (WealthState(time=1, wealth=-1, risky_asset_allocation=0, termination_time=3), InvestmentAction(risky_investment_amount=1)): 0.0, (WealthState(time=1, wealth=-1, risky_asset_allocation=1, termination_time=3), InvestmentAction(risky_investment_amount=0)): -14.231195443495643, (WealthState(time=2, wealth=-1, risky_asset_allocation=0, termination_time=3), InvestmentAction(risky_investment_amount=0)): -0.5, (WealthState(time=2, wealth=-1, risky_asset_allocation=1, termination_time=3), InvestmentAction(risky_investment_amount=1)): 0.0, (WealthState(time=2, wealth=-1, risky_asset_allocation=2, termination_time=3), InvestmentAction(risky_investment_amount=1)): 0.0, (WealthState(time=1, wealth=-1, risky_asset_allocation=0, termination_time=3), InvestmentAction(risky_investment_amount=0)): -1.1685564937639685, (WealthState(time=2, wealth=-1, risky_asset_allocation=1, termination_time=3), InvestmentAction(risky_investment_amount=0)): -1.8371129875279373, (WealthState(time=2, wealth=-1, risky_asset_allocation=2, termination_time=3), InvestmentAction(risky_investment_amount=0)): -26.62527789946335})\n",
      "\n",
      "defaultdict(<class 'float'>, {WealthState(time=0, wealth=-1, risky_asset_allocation=0, termination_time=3): InvestmentAction(risky_investment_amount=0), WealthState(time=1, wealth=-1, risky_asset_allocation=0, termination_time=3): InvestmentAction(risky_investment_amount=0), WealthState(time=1, wealth=-1, risky_asset_allocation=1, termination_time=3): InvestmentAction(risky_investment_amount=0), WealthState(time=2, wealth=-1, risky_asset_allocation=0, termination_time=3): InvestmentAction(risky_investment_amount=0), WealthState(time=2, wealth=-1, risky_asset_allocation=1, termination_time=3): InvestmentAction(risky_investment_amount=0), WealthState(time=2, wealth=-1, risky_asset_allocation=2, termination_time=3): InvestmentAction(risky_investment_amount=0)})\n"
     ]
    }
   ],
   "source": [
    "from __future__ import annotations\n",
    "## Setting up - State, Reward Transition, Actions, Reward\n",
    "from abc import ABC, abstractmethod\n",
    "from dataclasses import dataclass\n",
    "from collections import defaultdict\n",
    "from scipy.stats import binom\n",
    "import numpy as np\n",
    "from typing import Dict, Sequence\n",
    "import itertools\n",
    "import random\n",
    "import operator\n",
    "\n",
    "'''\n",
    "Initial Assumptions\n",
    "- Discrete Time\n",
    "- Discrete Returns: +/-1 (daily)\n",
    "- 1 Stock - Follows Binomial Distribution payout\n",
    "- Utility - CARA function for final step reward Constant Absolute Risk Aversion\n",
    "- T = 10 based on Assignment specification\n",
    "- No fractional investments (i.e. only units)\n",
    "- Assuming W_0 initial wealth = 0\n",
    "- Assume NO CONSUMPTION of wealth at any Time t<T\n",
    "- Unconstrained allocation amount\n",
    "'''\n",
    "\n",
    "ITERATIONS=3\n",
    "GAMMA=1\n",
    "COEFFICIENT_OF_ARA=1\n",
    "INVESTMENT_LIMIT=1 #Buy 1 stock per day\n",
    "RISK_FREE_RATE=0 #Assuming you're just letting your money sit there for now so you will never lose really\n",
    "PROBABILITY_ALPHA=0.5 #Probability of risky asset increasing\n",
    "INCREASE=1\n",
    "DECREASE=-1\n",
    "PRICE_RANGE=1 #[-1,1]\n",
    "\n",
    "'''State'''\n",
    "@dataclass(frozen=True)\n",
    "class WealthState:\n",
    "    time: int #time state I am in\n",
    "    wealth: int #for now it will be int\n",
    "    risky_asset_allocation: int\n",
    "    termination_time:int = ITERATIONS\n",
    "    \n",
    "    def __eq__(self, other):\n",
    "        return (self.time == other.time) and \\\n",
    "               (self.wealth == other.wealth) and \\\n",
    "               (self.risky_asset_allocation == other.risky_asset_allocation)\n",
    "    \n",
    "    def isTerminal(self):\n",
    "        return self.time == self.termination_time\n",
    "\n",
    "'''ACTIONS'''\n",
    "'''Only buy 1 stock for a given time step'''\n",
    "@dataclass(frozen=True)\n",
    "class InvestmentAction:\n",
    "    risky_investment_amount: int\n",
    "    \n",
    "    def __eq__(self, other):\n",
    "        return self.risky_investment_amount == other.risky_investment_amount\n",
    "    \n",
    "    #Can't short yet#\n",
    "    def action_to_next_state(self, ws: WealthState) -> WealthState:\n",
    "        new_state = WealthState(time=ws.time+1, \n",
    "                                wealth=ws.wealth,\n",
    "                                risky_asset_allocation=ws.risky_asset_allocation + self.risky_investment_amount\n",
    "                               )\n",
    "        return new_state\n",
    "    \n",
    "    @staticmethod\n",
    "    def get_all_actions(investment_limit: int) -> Sequence[InvestmentAction]:\n",
    "        all_actions = list()\n",
    "        for i in range(investment_limit+1):\n",
    "            action = InvestmentAction(risky_investment_amount=i) #you can choose not to invest too\n",
    "            all_actions.append(action)\n",
    "        \n",
    "        return all_actions\n",
    "    \n",
    "'''REWARD'''\n",
    "'''CARA UTILITY'''\n",
    "def cara_func(x :int, alpha=COEFFICIENT_OF_ARA) -> int:\n",
    "    return - np.exp(- alpha * x)/alpha\n",
    "\n",
    "def wealth_func(ws: WealthState, risky_asset_return: int) -> int:\n",
    "    risky_return = ws.risky_asset_allocation * risky_asset_return\n",
    "    #when negative that means im borrowing money to buy stocks\n",
    "    risk_free_return = max(0,(ws.wealth - ws.risky_asset_allocation)) * (1 + RISK_FREE_RATE) \n",
    "    return risky_return + risk_free_return  \n",
    "\n",
    "#Binomial Returns\n",
    "def expected_binomial_returns(time=ITERATIONS, probability=PROBABILITY_ALPHA) -> Dict:\n",
    "    values = [[0]]\n",
    "    for i in range(time):\n",
    "        root = values[i]\n",
    "        new_vals = []\n",
    "        for val in root:\n",
    "            new_vals += [val + 1, val -1]\n",
    "        \n",
    "        values += [new_vals] #Per index gives you the combinations on each iteration - building the binomial tree\n",
    "    \n",
    "    combinations = values[time]\n",
    "    sorted_prices = sorted({v for v in combinations})\n",
    "    \n",
    "    ##Probabilities\n",
    "    price_probs = {price: round(binom.pmf(index, time, probability),3) \n",
    "                   for index, price in enumerate(sorted_prices)}\n",
    "        \n",
    "    return price_probs\n",
    "\n",
    "#probability passed in for testing purposes - defaulted to global variable\n",
    "def reward_function(ws: WealthState, probability=PROBABILITY_ALPHA, alpha=COEFFICIENT_OF_ARA) -> float:\n",
    "    if ws.isTerminal():\n",
    "        expected_returns = expected_binomial_returns(ws.time,probability)\n",
    "        utility = 0\n",
    "        for price, probability in list(expected_returns.items()):\n",
    "            price_utility = cara_func(wealth_func(ws,price),alpha)\n",
    "            # print(price_utility)\n",
    "            #Remember price is stochastic as well - so calculating the expected price given the \n",
    "            #binomial returns at the very end\n",
    "            utility += price_utility * probability\n",
    "\n",
    "        return utility\n",
    "    else:\n",
    "        return 0.\n",
    "\n",
    "'''TRANSITIONS'''\n",
    "'''Returns a sequence indexed by time. Essentially, its a sequence of possible states at a given time assuming all actions\n",
    "are applied to each state'''\n",
    "def get_all_state_actions(iterations, available_actions, initial_state) -> Sequence[Dict[WealthState, Dict[WealthState, float]]]:\n",
    "    all_states = [{initial_state:{(a,a.action_to_next_state(initial_state)): \\\n",
    "                    1/len(available_actions) for a in available_actions}}]\n",
    "    prev_states = [initial_state]\n",
    "    for i in range(iterations-1):\n",
    "        next_states = [a.action_to_next_state(prev) for a in available_actions for prev in prev_states]\n",
    "        next_states_mapping = {}\n",
    "        for next_state in next_states:\n",
    "            #Assuming equal probability of moving into the next state\n",
    "            transitioned_states = {(a,a.action_to_next_state(next_state)):\n",
    "                           1/len(available_actions) for a in available_actions}\n",
    "            next_states_mapping[next_state]= transitioned_states\n",
    "        \n",
    "        all_states.append(next_states_mapping)\n",
    "        prev_states = next_states\n",
    "        \n",
    "    return all_states\n",
    "\n",
    "'''\n",
    "MDP PROCESS\n",
    "1. Decrement from time T back down to 0 to calculate the values for each state.\n",
    "2. each time_step: T-1 = r + discount * E[G_T|S] (but r = 0 for non terminal states so... :)\n",
    "'''\n",
    "initial_state = ws = WealthState(time=0,wealth=-1,risky_asset_allocation=0)\n",
    "all_actions = InvestmentAction.get_all_actions(investment_limit=INVESTMENT_LIMIT)\n",
    "all_state_actions = get_all_state_actions(ITERATIONS, all_actions, ws)\n",
    "\n",
    "#Define a state action reward mapping - for each time - state:{(action,next_state): reward}\n",
    "#Probably applicable for finite states only.\n",
    "def get_state_action_value_map(all_state_actions, reward_func=reward_function, gamma=GAMMA, iterations=ITERATIONS):\n",
    "    state_action_value_map = defaultdict(float)\n",
    "    for i in reversed(range(iterations)):\n",
    "        states_at_t = all_state_actions[i]\n",
    "        for (state_at_t) in states_at_t:\n",
    "            next_state_actions = list(states_at_t[state_at_t].items())\n",
    "            discount = gamma ** (iterations - i)\n",
    "            ##The assumption is becasue this is finite state, the state_value_map will have computed the\n",
    "            ##rewards at t+1 already cause this is going reverse time. Need to think about approximating later\n",
    "            next_states = [(action_state, probability) for action_state , probability in next_state_actions]\n",
    "            state_rewards = {s_a:reward_func(s_a[1]) * prob * discount if s_a[1].isTerminal()\n",
    "                             else sum(list(state_action_value_map[s_a[1]].values())) * prob * discount #not adding r because 0 for non-terminal\n",
    "                             for s_a, prob in next_states}\n",
    "            state_action_value_map[state_at_t] = state_rewards\n",
    "    \n",
    "    return state_action_value_map\n",
    "\n",
    "state_action_value_map=get_state_action_value_map(all_state_actions)\n",
    "#Initialize a random policy - randomly choose an action to determine an initial policy\n",
    "policy_0 = defaultdict(float)\n",
    "\n",
    "for _, states_actions_map in enumerate(all_state_actions):\n",
    "    [*states] = states_actions_map.keys()\n",
    "    for state in states:\n",
    "        action_states = [*states_actions_map[state].keys()]\n",
    "        # print(action_states)\n",
    "        probabilities = [*states_actions_map[state].values()]\n",
    "        chosen_action_state = random.choices(action_states, weights=probabilities)\n",
    "        chosen_action = [action for (action,state) in chosen_action_state][0]\n",
    "        policy_0[state] = chosen_action\n",
    "    \n",
    "###Policy Evaluation - policy for s -> action: I want value function\n",
    "def policy_evaluation(policy, state_action_value_map):\n",
    "    q_function = defaultdict(float)\n",
    "    for (state, action) in policy.items():\n",
    "        state_action_values = state_action_value_map[state]\n",
    "        action_value = state_action_values[(action, action.action_to_next_state(state))]\n",
    "        q_function[(state,action)] = action_value\n",
    "    \n",
    "    return q_function\n",
    "\n",
    "policy_evaluation(policy_0,state_action_value_map)\n",
    "\n",
    "###Value Iteration - greedy policy - choose the action from value function that gives you the highest expected reward\n",
    "def converged(q_function_1,q_function_2):\n",
    "    return max(abs(q_function_1[s] - q_function_2[s]) for s in q_function_1) < 1e-4\n",
    "\n",
    "q_function_0 = policy_evaluation(policy_0,state_action_value_map)\n",
    "q_function = q_function_0\n",
    "greedy_q_function = defaultdict(float)\n",
    "while not converged(q_function,greedy_q_function):\n",
    "    #Evaluate the greedy_q_function\n",
    "    greedy_policy = defaultdict(float)\n",
    "    for state_actions in all_state_actions:\n",
    "        for (state, actions) in state_actions.items():\n",
    "            action_values = {action: state_action_value_map[state][(action,action.action_to_next_state(state))] \n",
    "                         for action, _ in actions}\n",
    "            max_action = [action for action, value in action_values.items() if value == max(action_values.values())][0]\n",
    "            greedy_policy[state]=max_action\n",
    "    \n",
    "    q_function.update(greedy_q_function)\n",
    "    greedy_q_function.update(policy_evaluation(greedy_policy,state_action_value_map))\n",
    "\n",
    "print(greedy_q_function)\n",
    "print(\"\")\n",
    "print(greedy_policy)\n",
    "        "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "510fa7e9-662f-4b59-8a90-c67f9d6ce8cd",
   "metadata": {},
   "source": [
    "### Test Functions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "id": "98a13430-f2f8-4578-81f6-fac583d1a885",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "testBinomialReturnsWhenT_equals_1 (__main__.TestBinomialReturns) ... ok\n",
      "testBinomialReturnsWhenT_equals_2 (__main__.TestBinomialReturns) ... ok\n",
      "testBinomialReturnsWhenT_equals_2_Uneven_Chance (__main__.TestBinomialReturns) ... ok\n",
      "testBinomialReturnsWhenT_equals_3 (__main__.TestBinomialReturns) ... ok\n",
      "testCARA (__main__.TestCARAUtility) ... ok\n",
      "testGet_All_State_Actions_1_time_step (__main__.TestGetAllStateActions) ... ok\n",
      "testGet_All_State_Actions_2_time_step (__main__.TestGetAllStateActions) ... ok\n",
      "testGetStateActionValueMap_1_iteration (__main__.TestGetStateActionValueMap) ... ok\n",
      "testGetAllActions_Investment_Limit_1 (__main__.TestInvestmentAction) ... ok\n",
      "testNextState (__main__.TestInvestmentAction) ... ok\n",
      "testRewardWhenStateIsNonTerminal (__main__.TestRewardFunction) ... ok\n",
      "testRewardWhenStateIsTerminal_at_1 (__main__.TestRewardFunction) ... ok\n",
      "testRewardWhenStateIsTerminal_at_1_Uneven_Chance (__main__.TestRewardFunction) ... ok\n",
      "testRewardWhenStateIsTerminal_at_2 (__main__.TestRewardFunction) ... ok\n",
      "testWealthFunction_Price_0_0_Risky_Asset (__main__.TestWealthFunction) ... ok\n",
      "testWealthFunction_Price_0_1_Risky_Asset (__main__.TestWealthFunction) ... ok\n",
      "testWealthFunction_Price_1_0_Risky_Asset (__main__.TestWealthFunction) ... ok\n",
      "testWealthFunction_Price_1_1_Risky_Asset (__main__.TestWealthFunction) ... ok\n",
      "testWealthFunction_Price_2_1_Risky_Asset (__main__.TestWealthFunction) ... ok\n",
      "testWealthFunction_Price_3_1_Risky_Asset (__main__.TestWealthFunction) ... ok\n",
      "testWealthFunction_Price_3_2_Risky_Asset (__main__.TestWealthFunction) ... ok\n",
      "testWealthFunction_Price_neg_3_2_Risky_Asset (__main__.TestWealthFunction) ... ok\n",
      "testWealthFunction_Zero_Initial_Price_neg_3_2_Risky_Asset (__main__.TestWealthFunction) ... ok\n",
      "testWealthState (__main__.TestWealthState) ... "
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "defaultdict(<class 'float'>, {WealthState(time=0, wealth=0, risky_asset_allocation=0, termination_time=1): {(InvestmentAction(risky_investment_amount=1), WealthState(time=1, wealth=0, risky_asset_allocation=1, termination_time=1)): -1.3591409142295225, (InvestmentAction(risky_investment_amount=0), WealthState(time=1, wealth=0, risky_asset_allocation=0, termination_time=1)): -0.5}})\n",
      "defaultdict(<class 'float'>, {WealthState(time=0, wealth=0, risky_asset_allocation=0, termination_time=1): {(InvestmentAction(risky_investment_amount=1), WealthState(time=1, wealth=0, risky_asset_allocation=1, termination_time=1)): -1.3591409142295225, (InvestmentAction(risky_investment_amount=0), WealthState(time=1, wealth=0, risky_asset_allocation=0, termination_time=1)): -0.5}})\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "ok\n",
      "\n",
      "----------------------------------------------------------------------\n",
      "Ran 24 tests in 0.053s\n",
      "\n",
      "OK\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<unittest.main.TestProgram at 0x7fdc56a60190>"
      ]
     },
     "execution_count": 30,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import unittest\n",
    "\n",
    "def assert_lists_no_order(test_case, list1,list2):\n",
    "    for i in list1:\n",
    "        test_case.assertIn(i,list2)\n",
    "        \n",
    "    for i in list2:\n",
    "        test_case.assertIn(i,list1)\n",
    "        \n",
    "class TestWealthState(unittest.TestCase):\n",
    "    ws = WealthState(time=0,wealth=10,risky_asset_allocation=0)\n",
    "    \n",
    "    def testWealthState(self):\n",
    "        self.assertEqual(self.ws.time,0)\n",
    "        self.assertEqual(self.ws.wealth,10)\n",
    "        self.assertEqual(self.ws.risky_asset_allocation,0)\n",
    "\n",
    "class TestInvestmentAction(unittest.TestCase):\n",
    "    ia = InvestmentAction(risky_investment_amount=2)\n",
    "    ws = WealthState(time=0,wealth=10,risky_asset_allocation=0)\n",
    "    \n",
    "    def testNextState(self):\n",
    "        ns = self.ia.action_to_next_state(self.ws)\n",
    "        self.assertEqual(ns.time,1)\n",
    "        self.assertEqual(ns.wealth,10)\n",
    "        self.assertEqual(ns.risky_asset_allocation,2)\n",
    "\n",
    "    def testGetAllActions_Investment_Limit_1(self):\n",
    "        ia = InvestmentAction(risky_investment_amount=1)\n",
    "        actions = InvestmentAction.get_all_actions(1)\n",
    "        expected_actions = [\n",
    "            InvestmentAction(risky_investment_amount=1),\n",
    "            InvestmentAction(risky_investment_amount=0)\n",
    "        ]\n",
    "        assert_lists_no_order(self,actions,expected_actions)\n",
    "        \n",
    "class TestCARAUtility(unittest.TestCase):\n",
    "     def testCARA(self):\n",
    "        # -( e ^ (- alpha * Wt) )/alpha\n",
    "        self.assertEqual(cara_func(1, alpha=1),-1/np.e)\n",
    "        self.assertEqual(cara_func(1, alpha=2), - ((np.e ** (-2 * 1))/2))\n",
    "\n",
    "class TestWealthFunction(unittest.TestCase):\n",
    "    def testWealthFunction_Price_0_0_Risky_Asset(self):\n",
    "        ws = WealthState(time=0,wealth=10,risky_asset_allocation=0)\n",
    "        self.assertEqual(wealth_func(ws,0),10)\n",
    "        \n",
    "    def testWealthFunction_Price_1_0_Risky_Asset(self):\n",
    "        ws = WealthState(time=0,wealth=10,risky_asset_allocation=0)\n",
    "        self.assertEqual(wealth_func(ws,0),10)\n",
    "\n",
    "    def testWealthFunction_Price_0_1_Risky_Asset(self):\n",
    "        ws = WealthState(time=0,wealth=10,risky_asset_allocation=1)\n",
    "        self.assertEqual(wealth_func(ws,1),10)\n",
    "        \n",
    "    def testWealthFunction_Price_1_1_Risky_Asset(self):\n",
    "        ws = WealthState(time=0,wealth=10,risky_asset_allocation=1)\n",
    "        self.assertEqual(wealth_func(ws,1),10)\n",
    "        \n",
    "    def testWealthFunction_Price_2_1_Risky_Asset(self):\n",
    "        ws = WealthState(time=0,wealth=10,risky_asset_allocation=1)\n",
    "        self.assertEqual(wealth_func(ws,2),11)\n",
    "        \n",
    "    def testWealthFunction_Price_3_1_Risky_Asset(self):\n",
    "        ws = WealthState(time=0,wealth=10,risky_asset_allocation=1)\n",
    "        self.assertEqual(wealth_func(ws,3),12)\n",
    "\n",
    "    def testWealthFunction_Price_3_2_Risky_Asset(self):\n",
    "        ws = WealthState(time=0,wealth=10,risky_asset_allocation=2)\n",
    "        self.assertEqual(wealth_func(ws,3),14)\n",
    "        \n",
    "    def testWealthFunction_Price_neg_3_2_Risky_Asset(self):\n",
    "        ws = WealthState(time=0,wealth=10,risky_asset_allocation=2)\n",
    "        self.assertEqual(wealth_func(ws,-3),2)\n",
    "\n",
    "    def testWealthFunction_Zero_Initial_Price_neg_3_2_Risky_Asset(self):\n",
    "        ws = WealthState(time=0,wealth=0,risky_asset_allocation=2)\n",
    "        self.assertEqual(wealth_func(ws,-3),-6)\n",
    "\n",
    "class TestBinomialReturns(unittest.TestCase):\n",
    "    def testBinomialReturnsWhenT_equals_1(self):\n",
    "        #either +1 or -1 with 0.5 chance\n",
    "        returns = expected_binomial_returns(1,0.5)\n",
    "        self.assertEqual(returns,{1:0.5,-1:0.5})\n",
    "\n",
    "    def testBinomialReturnsWhenT_equals_2(self):\n",
    "        returns = expected_binomial_returns(2,0.5)\n",
    "        self.assertEqual(returns,{2:0.25,0:0.5,-2:0.25})\n",
    "\n",
    "    def testBinomialReturnsWhenT_equals_2_Uneven_Chance(self):\n",
    "        returns = expected_binomial_returns(2,0.6)\n",
    "        self.assertEqual(returns,{2:0.36,0:0.48,-2:0.16})\n",
    "        \n",
    "    def testBinomialReturnsWhenT_equals_3(self):\n",
    "        returns = expected_binomial_returns(3,0.5)\n",
    "        self.assertEqual(returns,{3:0.125,1:0.375,-1:0.375,-3:0.125})\n",
    "\n",
    "class TestRewardFunction(unittest.TestCase):\n",
    "    def testRewardWhenStateIsNonTerminal(self):\n",
    "        ws= WealthState(time=0,wealth=0,risky_asset_allocation=0)\n",
    "        self.assertEqual(reward_function(ws),0)\n",
    "    \n",
    "    def testRewardWhenStateIsTerminal_at_1(self):\n",
    "        ws= WealthState(time=1,wealth=0,risky_asset_allocation=1,termination_time=1)\n",
    "        ## 0.5 * -e(-1 * -1)/1 + 0.5 * -e(-1 * 1)/1 = expected utility given the prices\n",
    "        self.assertEqual(reward_function(ws,probability=0.5,alpha=1), (-np.e * 0.5) + (1/-np.e * 0.5))\n",
    "        \n",
    "    def testRewardWhenStateIsTerminal_at_2(self):\n",
    "        ws= WealthState(time=2,wealth=0,risky_asset_allocation=1,termination_time=2)\n",
    "        '''\n",
    "        0.25 * -e(-1 * -2)\n",
    "        0.5 * -e(-1 * 0)\n",
    "        0.25 * -e(-1 * 2)\n",
    "        '''\n",
    "        expected_utility = round((0.25 * -np.e ** (-1 * -2)) + (0.5 * -np.e ** (-1 * 0)) + (0.25 * -np.e ** (-1 * 2)),5)\n",
    "        self.assertEqual(round(reward_function(ws,probability=0.5,alpha=1),5), expected_utility)\n",
    "        \n",
    "    def testRewardWhenStateIsTerminal_at_1_Uneven_Chance(self):\n",
    "        ws= WealthState(time=1,wealth=0,risky_asset_allocation=1,termination_time=1)\n",
    "        ''' 0.6 * -e(-1 * -1)/1 + 0.4 * -e(-1 * 1)/1 = expected utility given the prices'''\n",
    "        reward = round(reward_function(ws,probability=0.6,alpha=1),5)\n",
    "        expected_reward = round((-np.e * 0.4) + (1/-np.e * 0.6),5)\n",
    "        self.assertEqual(reward,expected_reward)\n",
    "        \n",
    "class TestGetAllStateActions(unittest.TestCase):\n",
    "    def testGet_All_State_Actions_1_time_step(self):\n",
    "        ws= WealthState(time=0,wealth=0,risky_asset_allocation=0,termination_time=1)\n",
    "        actions = [InvestmentAction(risky_investment_amount=1),InvestmentAction(risky_investment_amount=0)]\n",
    "        all_state_actions = get_all_state_actions(1,actions,ws)\n",
    "        expected_state_actions = [{\n",
    "            ws: {\n",
    "                (InvestmentAction(risky_investment_amount=1),WealthState(time=1,wealth=0,risky_asset_allocation=1)):0.5,\n",
    "                (InvestmentAction(risky_investment_amount=0),WealthState(time=1,wealth=0,risky_asset_allocation=0)):0.5\n",
    "            }\n",
    "        }]\n",
    "        self.assertEqual(expected_state_actions,all_state_actions)\n",
    "        \n",
    "    def testGet_All_State_Actions_2_time_step(self):\n",
    "        ws= WealthState(time=0,wealth=0,risky_asset_allocation=0,termination_time=1)\n",
    "        actions = [InvestmentAction(risky_investment_amount=1),InvestmentAction(risky_investment_amount=0)]\n",
    "        all_state_actions = get_all_state_actions(2,actions,ws)\n",
    "        expected_state_actions = [{\n",
    "            ws: {\n",
    "                (InvestmentAction(risky_investment_amount=1),WealthState(time=1,wealth=0,risky_asset_allocation=1)):0.5,\n",
    "                (InvestmentAction(risky_investment_amount=0),WealthState(time=1,wealth=0,risky_asset_allocation=0)):0.5\n",
    "            }\n",
    "        },\n",
    "            {\n",
    "            WealthState(time=1,wealth=0,risky_asset_allocation=1): {\n",
    "                (InvestmentAction(risky_investment_amount=1),WealthState(time=2,wealth=0,risky_asset_allocation=2)):0.5,\n",
    "                (InvestmentAction(risky_investment_amount=0),WealthState(time=2,wealth=0,risky_asset_allocation=1)):0.5\n",
    "            },\n",
    "            WealthState(time=1,wealth=0,risky_asset_allocation=0): {\n",
    "                (InvestmentAction(risky_investment_amount=1),WealthState(time=2,wealth=0,risky_asset_allocation=1)):0.5,\n",
    "                (InvestmentAction(risky_investment_amount=0),WealthState(time=2,wealth=0,risky_asset_allocation=0)):0.5\n",
    "            }\n",
    "        },\n",
    "        ]\n",
    "        self.assertEqual(expected_state_actions,all_state_actions)\n",
    "\n",
    "class TestGetStateActionValueMap(unittest.TestCase):\n",
    "    def testGetStateActionValueMap_1_iteration(self):\n",
    "        gamma = 1\n",
    "        probability = 0.5\n",
    "        state_actions = [{\n",
    "            WealthState(time=0,wealth=0,risky_asset_allocation=0,termination_time=1): {\n",
    "                (InvestmentAction(risky_investment_amount=1),WealthState(time=1,wealth=0,risky_asset_allocation=1,termination_time=1)):0.5,\n",
    "                (InvestmentAction(risky_investment_amount=0),WealthState(time=1,wealth=0,risky_asset_allocation=0,termination_time=1)):0.5\n",
    "            }\n",
    "        }]\n",
    "        reward_function = lambda ws: -np.e ** ws.risky_asset_allocation\n",
    "        expected_state_action_value_map = defaultdict(float)\n",
    "        expected_state_action_value_map.update({\n",
    "            WealthState(time=0,wealth=0,risky_asset_allocation=0,termination_time=1):{\n",
    "                (InvestmentAction(risky_investment_amount=1),WealthState(time=1,wealth=0,risky_asset_allocation=1,termination_time=1)): -gamma * np.e ** 1 * probability,\n",
    "                (InvestmentAction(risky_investment_amount=0),WealthState(time=1,wealth=0,risky_asset_allocation=0,termination_time=1)): -gamma * np.e ** 0 * probability\n",
    "            }\n",
    "        })\n",
    "        result = get_state_action_value_map(state_actions,reward_func=reward_function,gamma=1,iterations=1)\n",
    "        print(result)\n",
    "        print(expected_state_action_value_map)\n",
    "        self.assertEqual(expected_state_action_value_map,result)\n",
    "        \n",
    "unittest.main(argv=[''], verbosity=2, exit=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "12a5666c-74a2-4614-9db4-b3907720ec3c",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
